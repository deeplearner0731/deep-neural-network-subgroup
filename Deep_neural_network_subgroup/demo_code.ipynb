{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a6ffd9-b4aa-4f23-8bc5-62c4ea2d629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import random\n",
    "import warnings\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Deep_learning_subgroup import ConcreteAutoencoderFeatureSelector\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, LeakyReLU,ReLU\n",
    "from keras import backend as K\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d53ff181-7215-467c-8ef2-7dde1039a9c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 466us/step\n",
      "7/7 [==============================] - 0s 762us/step\n",
      "feature importance\n",
      "{'0': 1.0, '3': 1.0}\n",
      "training auc\n",
      "0.5069878924805933\n",
      "testing auc\n",
      "0.5682758620689655\n"
     ]
    }
   ],
   "source": [
    "val_num=1\n",
    "df_result_box=pd.DataFrame()\n",
    "for po in [0]:\n",
    "    for pre in [0.7]:\n",
    "        best_train=[]\n",
    "        best_test=[]\n",
    "        best_feature=[]\n",
    "        best_seed=[]\n",
    "        for kk in range (val_num):\n",
    "            train_num=random.sample(range(0,1000), 800)\n",
    "            test_num=list(set(range(0,1000))-set(train_num))\n",
    "            max_auc=0\n",
    "            data_simulation= pd.read_csv('/ui/abv/liuzx18/deep learning/simulation_data/simulation_case1_0816/{}contious_intersection_{}.csv'.format(po,pre)).iloc[train_num,]\n",
    "            data_simulation_test= pd.read_csv('/ui/abv/liuzx18/deep learning/simulation_data/simulation_case1_0816/{}contious_intersection_{}.csv'.format(po,pre)).iloc[test_num,]\n",
    "            del data_simulation['Unnamed: 0']\n",
    "            del data_simulation_test['Unnamed: 0']\n",
    "            x_df=data_simulation[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']]\n",
    "            X_=np.array(x_df).astype(np.float)\n",
    "            x_df_test=data_simulation_test[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']]\n",
    "            X_test=np.array(x_df_test).astype(np.float)\n",
    "            y_dummy=np.array(data_simulation[['y']]).astype(np.float)\n",
    "\n",
    "            y_dummy=y_dummy.reshape(data_simulation.shape[0],1)\n",
    "\n",
    "            y=y_dummy\n",
    "\n",
    "            trt_=data_simulation[['treatment']]\n",
    "            g_real=data_simulation[['sigpo']]\n",
    "            g_real_test=data_simulation_test[['sigpo']]\n",
    "\n",
    "            logreg = LogisticRegression()\n",
    "            logreg.fit(X_,trt_)\n",
    "            pi_x = logreg.predict_proba(X_)\n",
    "            pi_train=pi_x[:,1]\n",
    "\n",
    "            X_train_trt=np.where(trt_==1,1,-1)\n",
    "\n",
    "            feature_select={}\n",
    "            loss='A'\n",
    "            ep=10\n",
    "            lr=0.1\n",
    "            def decoder(x):\n",
    "                x = Dense(128)(x)\n",
    "                x = ReLU()(x)\n",
    "                #x = Dropout(0.1)(x)\n",
    "                x = Dense(64)(x)\n",
    "                x = ReLU()(x)\n",
    "                x = Dense(32)(x)\n",
    "                x = ReLU()(x)\n",
    "                #x = Dropout(0.1)(x)\n",
    "                x = Dense(1)(x)\n",
    "\n",
    "                return x\n",
    "\n",
    "            result=[]\n",
    "            \n",
    "            selector = ConcreteAutoencoderFeatureSelector(\n",
    "              K=8, output_function=decoder, batch_size=1000, num_epochs=ep,\n",
    "              loss_name='A', learning_rate=lr, start_temp=10.0, min_temp=0.01,\n",
    "              trt=X_train_trt.astype(np.float32),\n",
    "              pi=pi_train.astype(np.float32),\n",
    "              ver=0)\n",
    "            \n",
    "            model_1=selector.fit(X_, y, X_, y)\n",
    "            #selector.fit(geno_np_train, y, geno_np_train,y)\n",
    "            #selector.fit(K.eval(geno_np_train), K.eval(y_noise_train), K.eval(geno_np_train), K.eval(y_noise_train))\n",
    "            y_pred=model_1.model.predict(X_)\n",
    "            auc = roc_auc_score(-g_real.astype(int), y_pred)\n",
    "            #print('auc {}',format(auc))\n",
    "            y_pred_test=model_1.model.predict(X_test)\n",
    "            auc_test = roc_auc_score(-g_real_test.astype(int), y_pred_test)\n",
    "            #print('test auc {}',format(auc_test))\n",
    "\n",
    "           \n",
    "        best_f=selector.get_support(indices = True)\n",
    "      \n",
    "        best_feature.append(best_f)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        df_result_box['com_{}_{}'.format(po,pre)]=best_test\n",
    "        \n",
    "        rank_feature=[]\n",
    "        for j in best_feature:\n",
    "            dic_result={}\n",
    "            for k in np.unique(j):\n",
    "                dic_result[str(k)]=Counter(j)[k]\n",
    "            rank_feature.append(sorted(dic_result, key=dic_result.get, reverse=True))\n",
    "\n",
    "\n",
    "        dic_r={}\n",
    "        result_top2=rank_feature[0][0:2]\n",
    "        for d in range(1,len(rank_feature)):\n",
    "            result_top2=result_top2+rank_feature[d][0:2]\n",
    "        rank_feature_top2=[int(i) for i in result_top2]\n",
    "        for d in np.unique(rank_feature_top2):\n",
    "            dic_r[str(d)]=Counter(rank_feature_top2)[d]/float(len(rank_feature))\n",
    "        print('feature importance')\n",
    "        print(dic_r)\n",
    "        \n",
    "        print('training auc')\n",
    "        print(auc)\n",
    "        \n",
    "        print('testing auc')\n",
    "        print(auc_test)\n",
    "\n",
    "        dic=pd.DataFrame(dic_r.items())\n",
    "        dic.columns=['feature','precentage']\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372472cc-532c-4766-8645-75e2b9734669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-v2]",
   "language": "python",
   "name": "conda-env-.conda-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
